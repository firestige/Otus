# Otus é¡¹ç›®æŠ€æœ¯è¯„ä¼°æŠ¥å‘Š

**è¯„ä¼°æ—¥æœŸ**: 2026-02-17  
**è¯„ä¼°äºº**: Go è½¯ä»¶ä¸“å®¶ã€ç½‘ç»œå·¥ç¨‹å¸ˆã€å¯è§‚æµ‹æ€§ä¸“å®¶  
**é¡¹ç›®ç‰ˆæœ¬**: v0.1.0-dev  
**ä»£ç è¡Œæ•°**: ~13,376 è¡Œ Go ä»£ç   
**æµ‹è¯•æ–‡ä»¶**: 23 ä¸ªæµ‹è¯•æ–‡ä»¶

---

## æ‰§è¡Œæ‘˜è¦

Otus æ˜¯ä¸€ä¸ª**è®¾è®¡ä¼˜ç§€ä½†å®ç°ä¸å®Œæ•´**çš„é«˜æ€§èƒ½è¾¹ç¼˜ç½‘ç»œåŒ…æ•è·ä¸è§‚æµ‹ç³»ç»Ÿã€‚å…¶æ¶æ„ç†å¿µï¼ˆæ’ä»¶åŒ–ã€å•çº¿ç¨‹ Pipelineã€é™æ€ç¼–è¯‘ï¼‰ç¬¦åˆè¾¹ç¼˜åœºæ™¯çš„æ€§èƒ½è¦æ±‚ï¼Œä½†ä»£ç å®ç°ä¸­å­˜åœ¨å¤šä¸ª**ä¸¥é‡ç¼ºé™·**ï¼ŒåŒ…æ‹¬èµ„æºæ³„æ¼ã€ç«æ€æ¡ä»¶å’ŒæŒ‡æ ‡è®¡ç®—é”™è¯¯ï¼Œéœ€è¦åœ¨ç”Ÿäº§éƒ¨ç½²å‰ä¿®å¤ã€‚

### æ ¸å¿ƒå‘ç°

| ç±»åˆ« | å‘ç°æ•°é‡ | ä¸¥é‡æ€§åˆ†å¸ƒ |
|------|---------|-----------|
| **è®¾è®¡ä¸å®ç°ä¸ä¸€è‡´** | 5 | é«˜å± 3, ä¸­å± 2 |
| **æ½œåœ¨ Bug** | 8 | é«˜å± 3, ä¸­å± 5 |
| **æ€§èƒ½é—®é¢˜** | 5 | ä¸­å± 4, ä½å± 1 |
| **å¯ç»´æŠ¤æ€§é—®é¢˜** | 6 | ä¸­å± 3, ä½å± 3 |
| **å¯æ‰©å±•æ€§é—®é¢˜** | 6 | ä¸­å± 4, ä½å± 2 |

### æ¨èè¡ŒåŠ¨

1. **ç«‹å³ä¿®å¤**ï¼ˆç”Ÿäº§é˜»å¡ï¼‰: èµ„æºæ³„æ¼ï¼ˆTask å¯åŠ¨å¤±è´¥æ¸…ç†ï¼‰ã€ç«æ€æ¡ä»¶ï¼ˆsendBuffer å…³é—­ï¼‰ã€æŒ‡æ ‡é”™è¯¯ï¼ˆstatsCollectorLoopï¼‰
2. **çŸ­æœŸä¼˜åŒ–**ï¼ˆ1-2å‘¨ï¼‰: é…ç½®åŒ–ç¡¬ç¼–ç å€¼ã€è¡¥å……å•å…ƒæµ‹è¯•ã€å®Œå–„é”™è¯¯å¤„ç†
3. **é•¿æœŸæ”¹è¿›**ï¼ˆä¸‹ä¸€ç‰ˆæœ¬ï¼‰: ç§»é™¤å•ä»»åŠ¡é™åˆ¶ã€å®ç°çƒ­åŠ è½½ã€å¢å¼ºæ’ä»¶ç”Ÿå‘½å‘¨æœŸ

---

## ä¸€ã€è®¾è®¡ä¸å®ç°ä¸ä¸€è‡´åˆ†æ

### 1.1 ä¸¥é‡ç¼ºé™·ï¼šTask å¯åŠ¨å¤±è´¥æ—¶çš„èµ„æºæ³„æ¼

**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ **é«˜å±** - å¯¼è‡´ç”Ÿäº§ç¯å¢ƒèµ„æºè€—å°½

#### é—®é¢˜æè¿°

æ ¹æ®æ¶æ„æ–‡æ¡£ `doc/architecture.md`ï¼ŒTask åˆ›å»ºéµå¾ªä¸¥æ ¼çš„ 7 é˜¶æ®µæµç¨‹ï¼š

```
Phase 1: Validate â†’ Phase 2: Resolve â†’ Phase 3: Construct â†’ Phase 4: Init â†’ 
Phase 5: Wire â†’ Phase 6: Assemble â†’ Phase 7: Start
```

æ–‡æ¡£æ˜ç¡®æŒ‡å‡ºåœ¨ **Phase 7 å¯åŠ¨å¤±è´¥æ—¶åº”è¿›è¡Œå›æ»šæ¸…ç†**ï¼Œä½†å®é™…ä»£ç å¹¶æœªå®ç°ã€‚

**ä½ç½®**: `internal/task/manager.go:214-216`

```go
// å½“å‰å®ç°ï¼ˆé”™è¯¯ï¼‰
if err := task.Start(); err != nil {
    return fmt.Errorf("task start failed: %w", err)  // âŒ ç›´æ¥è¿”å›ï¼Œæœªæ¸…ç†å·²å¯åŠ¨çš„èµ„æº
}
```

**å½±å“åˆ†æ**:

åœ¨ `internal/task/task.go:155-215` çš„ `Start()` æ–¹æ³•ä¸­ï¼ŒReporter çš„å¯åŠ¨é¡ºåºå¦‚ä¸‹ï¼š

```go
// Line 169-178: å¯åŠ¨æ‰€æœ‰ Reporters
for i, rep := range t.Reporters {
    if err := rep.Start(ctx); err != nil {
        return fmt.Errorf("start reporter %d failed: %w", i, err)
    }
    slog.Info("reporter started", "index", i, "type", reflect.TypeOf(rep))
}
```

å¦‚æœç¬¬ 3 ä¸ª Reporter å¯åŠ¨å¤±è´¥ï¼Œå‰ 2 ä¸ª Reporter å·²ç»è°ƒç”¨äº† `Start()`ï¼Œä½†é”™è¯¯ç›´æ¥è¿”å›åˆ° `manager.go` åï¼š
- âœ… å‰ 2 ä¸ª Reporter çš„ goroutine ä»åœ¨è¿è¡Œ
- âœ… Kafka è¿æ¥ä¿æŒæ‰“å¼€
- âœ… æ–‡ä»¶å¥æŸ„æœªå…³é—­
- âŒ Task å¯¹è±¡è¢«ä¸¢å¼ƒï¼Œæ— æ³•åç»­è°ƒç”¨ `Stop()` æ¸…ç†

**å¤ç°æ­¥éª¤**:

```bash
# é…ç½® 3 ä¸ª Reporterï¼Œå…¶ä¸­ Kafka-2 é…ç½®é”™è¯¯çš„ broker åœ°å€
tasks:
  - id: test-leak
    reporters:
      - name: console      # æˆåŠŸå¯åŠ¨
      - name: kafka        # æˆåŠŸå¯åŠ¨
        config: {topic: "valid-topic", brokers: ["kafka:9092"]}
      - name: kafka        # å¯åŠ¨å¤±è´¥ï¼ˆè¿æ¥è¶…æ—¶ï¼‰
        config: {topic: "test", brokers: ["invalid-host:9092"]}

# è¿è¡Œåè§‚å¯Ÿ
ps aux | grep otus  # å‘ç°å­¤å„¿ goroutineï¼ˆé€šè¿‡ pprofï¼‰
lsof -p <otus-pid>  # å‘ç°æ³„æ¼çš„ Kafka TCP è¿æ¥
```

**ä¿®å¤æ–¹æ¡ˆ**:

```go
// internal/task/manager.go:214-220
if err := task.Start(); err != nil {
    // å›æ»šï¼šåœæ­¢æ‰€æœ‰å·²å¯åŠ¨çš„ Reporter
    slog.Warn("task start failed, rolling back", "error", err)
    
    stopCtx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()
    
    for i, rep := range task.Reporters {
        if stopErr := rep.Stop(stopCtx); stopErr != nil {
            slog.Error("failed to stop reporter during rollback", 
                      "index", i, "error", stopErr)
        }
    }
    
    return fmt.Errorf("task start failed: %w", err)
}
```

**æ¶æ„è®¾è®¡å¯¹æ¯”**:

| è®¾è®¡æ–‡æ¡£è¦æ±‚ | å®é™…å®ç° | ç¬¦åˆåº¦ |
|-------------|---------|--------|
| "ä¸¥æ ¼ 7 é˜¶æ®µï¼Œå¤±è´¥å›æ»š" | æ— å›æ»šé€»è¾‘ | âŒ 0% |
| "èµ„æºç”Ÿå‘½å‘¨æœŸç®¡ç†" | éƒ¨åˆ†èµ„æºæ³„æ¼ | âš ï¸ 50% |
| "é”™è¯¯æ¢å¤æœºåˆ¶" | ä»…æ—¥å¿—è®°å½• | âŒ 0% |

---

### 1.2 ä¸¥é‡ç¼ºé™·ï¼šstatsCollectorLoop æŒ‡æ ‡è®¡ç®—é”™è¯¯

**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ **é«˜å±** - å¯¼è‡´ç›‘æ§æ•°æ®å®Œå…¨é”™è¯¯

#### é—®é¢˜æè¿°

æ¶æ„è®¾è®¡ä¸­ Task æ”¯æŒä¸¤ç§ Capturer éƒ¨ç½²æ¨¡å¼ï¼š
- **Binding æ¨¡å¼**: N ä¸ª Capturer å®ä¾‹ï¼ˆæ¯ä¸ªç»‘å®š AF_PACKET é˜Ÿåˆ—ï¼‰
- **Dispatch æ¨¡å¼**: 1 ä¸ª Capturer + åº”ç”¨å±‚åˆ†å‘

åœ¨ **Binding æ¨¡å¼**ä¸‹ï¼Œ`statsCollectorLoop()` ä½¿ç”¨**å…¨å±€å˜é‡**å­˜å‚¨ä¸Šä¸€æ¬¡çš„è®¡æ•°å™¨å€¼ï¼Œå¯¼è‡´å¤š Capturer åœºæ™¯ä¸‹ Delta è®¡ç®—å®Œå…¨é”™è¯¯ã€‚

**ä½ç½®**: `internal/task/task.go:470-521`

```go
// Line 475-476: å…¨å±€å˜é‡ï¼Œä»…åˆå§‹åŒ–ä¸€æ¬¡
var lastPacketsReceived uint64  // âŒ å¯¹æ‰€æœ‰ Capturer å…±äº«
var lastPacketsDropped uint64

// Line 488-495: å¾ªç¯å¤„ç†å¤šä¸ª Capturer
for i, cap := range t.Capturers {
    stats := cap.Stats()
    
    // âŒ ç¬¬ 2 ä¸ª Capturer çš„ stats å€¼ä¼šè¦†ç›–ç¬¬ 1 ä¸ªçš„ lastPacketsReceived
    deltaReceived := stats.PacketsReceived - lastPacketsReceived
    deltaDropped := stats.PacketsDropped - lastPacketsDropped
    
    // æ›´æ–°å…¨å±€è®¡æ•°å™¨ â†’ ä¸‹ä¸€ä¸ª Capturer è¯»å–åˆ°é”™è¯¯çš„ "ä¸Šæ¬¡å€¼"
    lastPacketsReceived = stats.PacketsReceived
    lastPacketsDropped = stats.PacketsDropped
}
```

**å½±å“ç¤ºä¾‹**ï¼ˆ3 ä¸ª Capturer çš„ Binding æ¨¡å¼ï¼‰:

| æ—¶åˆ» | Capturer | PacketsReceived | lastPacketsReceived | è®¡ç®—çš„ Delta | å®é™…åº”è¯¥æ˜¯ |
|------|---------|-----------------|--------------------|--------------|-----------| 
| T1 | Cap-0 | 10000 | 0 | **10000** âœ… | 10000 |
| T1 | Cap-1 | 8000 | 10000 | **-2000** âŒ | 8000 |
| T1 | Cap-2 | 12000 | 8000 | **4000** âŒ | 12000 |
| T2 | Cap-0 | 25000 | 12000 | **13000** âŒ | 15000 |
| T2 | Cap-1 | 20000 | 25000 | **-5000** âŒ | 12000 |

**Prometheus å½±å“**:

```promql
# é”™è¯¯çš„ç´¯ç§¯é€Ÿç‡ï¼ˆDelta å¯èƒ½ä¸ºè´Ÿæˆ–å·¨å¤§å€¼ï¼‰
rate(otus_capture_packets_total[5m])

# å¯¼è‡´å‘Šè­¦è¯¯æŠ¥
otus_capture_drops_total - otus_capture_drops_total offset 5m > 1000
```

**ä¿®å¤æ–¹æ¡ˆ**:

```go
// internal/task/task.go:470-521
func (t *Task) statsCollectorLoop() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()
    
    // ä¿®å¤ï¼šä½¿ç”¨ map å­˜å‚¨æ¯ä¸ª Capturer çš„ä¸Šæ¬¡çŠ¶æ€
    lastStats := make(map[int]plugin.CaptureStats, len(t.Capturers))
    
    for {
        select {
        case <-ticker.C:
            for i, cap := range t.Capturers {
                current := cap.Stats()
                last := lastStats[i]  // é»˜è®¤é›¶å€¼
                
                deltaReceived := current.PacketsReceived - last.PacketsReceived
                deltaDropped := current.PacketsDropped - last.PacketsDropped
                
                // é˜²æ­¢è®¡æ•°å™¨é‡ç½®å¯¼è‡´çš„ä¸‹æº¢
                if current.PacketsReceived < last.PacketsReceived {
                    deltaReceived = current.PacketsReceived
                }
                if current.PacketsDropped < last.PacketsDropped {
                    deltaDropped = current.PacketsDropped
                }
                
                t.metrics.CapturePackets.Add(deltaReceived)
                t.metrics.CaptureDrops.Add(deltaDropped)
                
                lastStats[i] = current  // æ›´æ–°è¯¥ Capturer çš„çŠ¶æ€
            }
        case <-t.ctx.Done():
            return
        }
    }
}
```

---

### 1.3 ä¸¥é‡ç¼ºé™·ï¼šTask.Stop() ä¸­çš„ Channel å…³é—­ç«æ€

**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ **é«˜å±** - å¯èƒ½å¯¼è‡´ panic

#### é—®é¢˜æè¿°

æ¶æ„æ–‡æ¡£è¦æ±‚ "shutdown é¡ºåºä¸ºåå‘ä¾èµ–é¡ºåº"ï¼š`Capturer â†’ Pipeline â†’ Sender â†’ Reporter`ã€‚

ä½†å®é™…ä»£ç åœ¨å…³é—­ `sendBuffer` channel æ—¶å­˜åœ¨ç«æ€æ¡ä»¶ã€‚

**ä½ç½®**: `internal/task/task.go:256-258`

```go
// Step 4: Cancel context and close sendBuffer
t.cancel()                 // âŒ å¼‚æ­¥ä¿¡å·ï¼Œä¸ä¿è¯ senderLoop ç«‹å³é€€å‡º
close(t.sendBuffer)        // âŒ å¯èƒ½æ­¤æ—¶ senderLoop ä»åœ¨è¯»å–

// Step 5: Wait for sender to finish draining sendBuffer
<-t.doneCh                 // âš ï¸ å¤ªæ™šäº†ï¼Œchannel å·²å…³é—­
```

**ç«æ€çª—å£**:

```
Timeline:
  T1: t.cancel()                  â†’ ctx.Done() ä¿¡å·å‘å‡º
  T2: close(t.sendBuffer)         â†’ channel å…³é—­
  T3: senderLoop æ£€æµ‹åˆ° ctx.Done() â†’ é€€å‡º select
  T4: senderLoop å°è¯•è¯»å– sendBuffer â†’ panic: "send on closed channel"
```

`internal/task/task.go:413-446` çš„ `senderLoop()` é€»è¾‘ï¼š

```go
func (t *Task) senderLoop() {
    defer close(t.doneCh)
    
    for {
        select {
        case <-t.ctx.Done():
            // âš ï¸ æ£€æµ‹åˆ°å–æ¶ˆï¼Œä½† sendBuffer å¯èƒ½å·²å…³é—­
            t.flushSendBuffer()  // å°è¯•è¯»å– sendBuffer
            return
        case pkt := <-t.sendBuffer:  // âŒ å¯èƒ½åœ¨ close() åæ‰§è¡Œ
            // ...
        }
    }
}
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼ˆåŒæ­¥ç­‰å¾… senderLoop é€€å‡ºåå†å…³é—­ï¼‰:

```go
// internal/task/task.go:250-260
// Step 4: å…ˆå–æ¶ˆ context
t.cancel()

// Step 5: ç­‰å¾… senderLoop è‡ªç„¶é€€å‡ºï¼ˆé€šè¿‡ ctx.Done()ï¼‰
<-t.doneCh

// Step 6: æ­¤æ—¶å®‰å…¨å…³é—­ channelï¼ˆsenderLoop å·²é€€å‡ºï¼‰
close(t.sendBuffer)
```

---

### 1.4 ä¸­å±ç¼ºé™·ï¼šDaemon.Stop() æœªæ¸…ç†ä¿¡å·å¤„ç†å™¨

**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ **ä¸­å±** - å¯èƒ½å¯¼è‡´ goroutine æ³„æ¼

**ä½ç½®**: `internal/daemon/daemon.go:174-209, 122-165`

`Run()` æ–¹æ³•ä¸­å¯åŠ¨ä¿¡å·å¤„ç† goroutineï¼š

```go
// Line 174
sigChan := make(chan os.Signal, 1)
signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

for {
    select {
    case sig := <-sigChan:  // âŒ æœªåœ¨ Stop() ä¸­è°ƒç”¨ signal.Stop(sigChan)
        // ...
    }
}
```

æ ¹æ® Go æ–‡æ¡£ï¼Œ`signal.Notify()` ä¼šå¯åŠ¨å†…éƒ¨ goroutine ç›‘å¬ä¿¡å·ï¼Œéœ€è¦æ˜¾å¼è°ƒç”¨ `signal.Stop()` æ¥åœæ­¢ã€‚

**ä¿®å¤**:

```go
// internal/daemon/daemon.go:150-165 çš„ Stop() æ–¹æ³•æœ«å°¾æ·»åŠ 
func (d *Daemon) Stop() error {
    // ... existing code ...
    
    // æ–°å¢ï¼šåœæ­¢ä¿¡å·å¤„ç†
    if d.sigChan != nil {
        signal.Stop(d.sigChan)
        close(d.sigChan)
    }
    return nil
}

// åœ¨ç»“æ„ä½“ä¸­æ·»åŠ å­—æ®µ
type Daemon struct {
    // ... existing fields ...
    sigChan chan os.Signal
}
```

---

### 1.5 ä¸­å±ç¼ºé™·ï¼šFlow Registry ç¼ºå°‘èšåˆæŒ‡æ ‡

**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ **ä¸­å±** - ç›‘æ§è¦†ç›–ä¸å®Œæ•´

æ¶æ„æ–‡æ¡£å£°æ˜ "å•ä»»åŠ¡ç›‘æ§" èƒ½åŠ›ï¼Œä½† `statsCollectorLoop()` ä»…æ”¶é›† **per-Capturer** æŒ‡æ ‡ï¼Œæœªæä¾›ä»»åŠ¡çº§èšåˆã€‚

**ç¼ºå¤±æŒ‡æ ‡**:

```promql
# å½“å‰ä»…æœ‰
otus_capture_packets_total{task="sip", capturer="0"}
otus_capture_packets_total{task="sip", capturer="1"}

# ç¼ºå¤±ï¼ˆéœ€æ‰‹åŠ¨èšåˆï¼‰
sum(rate(otus_capture_packets_total{task="sip"}[5m])) by (task)
```

**å½±å“**: è¿ç»´éœ€è‡ªè¡Œç¼–å†™ PromQL èšåˆæŸ¥è¯¢ï¼Œå¢åŠ å¤æ‚åº¦ã€‚

**å»ºè®®**: æ·»åŠ æ—  capturer label çš„ä»»åŠ¡çº§æŒ‡æ ‡ï¼š

```go
t.metrics.TaskTotalPackets.Add(deltaSum)  // æ–°å¢
```

---

## äºŒã€æ½œåœ¨ Bug åˆ†æ

### 2.1 é«˜å±ï¼šdispatchLoop çš„é›¶é™¤ Panic

**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ **é«˜å±**

**ä½ç½®**: `internal/task/task.go:315`

```go
idx := flowHash(pkt) % uint32(numPipelines)  // âŒ å¦‚æœ numPipelines = 0
```

**è§¦å‘æ¡ä»¶**: é…ç½®æ–‡ä»¶ä¸­ `workers: 0` ä¸”æœªæ­£ç¡®å¤„ç†é»˜è®¤å€¼é€»è¾‘ã€‚

**ä¿®å¤**:

```go
// internal/task/task.go:188-201
if t.config.DispatchMode == "dispatch" {
    if numPipelines == 0 {
        return fmt.Errorf("dispatch mode requires workers > 0")
    }
    // ...
}
```

---

### 2.2 é«˜å±ï¼šStats Delta ä¸‹æº¢é£é™©

**ä½ç½®**: `internal/task/task.go:488-489`

```go
deltaReceived := stats.PacketsReceived - lastPacketsReceived  // âŒ uint64 ä¸‹æº¢
```

**åœºæ™¯**: Capturer é‡å¯æˆ–è®¡æ•°å™¨é‡ç½®æ—¶ï¼Œæ–°å€¼ < æ—§å€¼ã€‚

**å½±å“**: Delta å˜æˆå·¨å¤§æ­£æ•°ï¼ˆ2^64 - diffï¼‰ï¼Œæ±¡æŸ“ Prometheus æ•°æ®ã€‚

**ä¿®å¤**: è§ 1.2 çš„ä¿®å¤æ–¹æ¡ˆï¼ˆå¢åŠ ä¸‹æº¢æ£€æµ‹ï¼‰ã€‚

---

### 2.3 ä¸­å±ï¼šKafka Consumer å…³é—­é”™è¯¯å¤„ç†ä¸å®Œæ•´

**ä½ç½®**: `internal/daemon/daemon.go:125-131`

```go
if d.kafkaConsumer != nil {
    if err := d.kafkaConsumer.Stop(); err != nil {
        slog.Error("error stopping kafka consumer", "error", err)
        // âŒ å³ä½¿å‡ºé”™ï¼Œä»éœ€å…³é—­åº•å±‚è¿æ¥
    }
}
```

**é—®é¢˜**: `Stop()` è¿”å›é”™è¯¯æ—¶ï¼ŒKafka reader å¯èƒ½ä»å¤„äºåŠå¼€çŠ¶æ€ã€‚

**ä¿®å¤**:

```go
if d.kafkaConsumer != nil {
    _ = d.kafkaConsumer.Stop()  // å¿½ç•¥é”™è¯¯ï¼Œç¡®ä¿ Close() è¢«è°ƒç”¨
}
```

---

### 2.4 ä¸­å±ï¼šPipeline Output Channel æ»¡æ—¶çš„ä¸¢åŒ…æœªè®°å½•è°ƒç”¨æ ˆ

**ä½ç½®**: `internal/pipeline/pipeline.go:83-88`

```go
default:
    // Output channel full, drop packet
    p.metrics.Dropped.Add(1)  // âŒ æ— æ—¥å¿—ï¼Œæ— è°ƒç”¨æ ˆ
}
```

**å½±å“**: ç”Ÿäº§ç¯å¢ƒéš¾ä»¥æ’æŸ¥ä¸¢åŒ…åŸå› ï¼ˆæ˜¯ Reporter æ…¢ï¼Ÿè¿˜æ˜¯é…ç½®é—®é¢˜ï¼Ÿï¼‰ã€‚

**å»ºè®®**: æ·»åŠ é‡‡æ ·æ—¥å¿—ï¼ˆæ¯ 1000 æ¬¡è®°å½•ä¸€æ¬¡ï¼‰ï¼š

```go
if atomic.AddUint64(&p.dropCount, 1)%1000 == 0 {
    slog.Warn("pipeline output full, dropping packets", 
             "total_dropped", p.dropCount)
}
```

---

### 2.5 ä¸­å±ï¼šFlow Registry Count() çš„æ€§èƒ½é—®é¢˜

**ä½ç½®**: `internal/task/flow_registry.go:53-59`

```go
func (r *FlowRegistry) Count() int {
    count := 0
    r.flows.Range(func(_, _ interface{}) bool {
        count++
        return true
    })
    return count
}
```

**é—®é¢˜**: 
- `sync.Map.Range()` éœ€è¦éå†æ‰€æœ‰æ¡ç›®
- **O(n)** å¤æ‚åº¦ï¼Œåœ¨é«˜æµé‡åœºæ™¯ï¼ˆ10ä¸‡+ flowsï¼‰å¯èƒ½å½±å“æ€§èƒ½
- å¦‚æœé¢‘ç¹è°ƒç”¨ï¼ˆå¦‚æ¯ç§’ä¸€æ¬¡ï¼‰ï¼Œä¼šé€ æˆé”ç«äº‰

**å½±å“**: è‹¥ `Count()` è¢«åŠ å…¥ metrics æ”¶é›†ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œä½†å¯èƒ½æœªæ¥æ·»åŠ ï¼‰ï¼Œä¼šé™ä½ååé‡ã€‚

**å»ºè®®**: 
1. ä½¿ç”¨ `atomic.Int64` ç»´æŠ¤è®¡æ•°å™¨ï¼š
```go
type FlowRegistry struct {
    flows sync.Map
    count atomic.Int64  // æ–°å¢
}

func (r *FlowRegistry) Register(key, value interface{}) {
    r.flows.Store(key, value)
    r.count.Add(1)  // å¢åŠ 
}

func (r *FlowRegistry) Count() int {
    return int(r.count.Load())  // O(1)
}
```

2. æˆ–æ–‡æ¡£å£°æ˜ `Count()` ä»…ç”¨äºè°ƒè¯•ï¼Œä¸åº”åœ¨ç”Ÿäº§ç¯å¢ƒé«˜é¢‘è°ƒç”¨ã€‚

---

### 2.6 ä½å±ï¼šTask State è½¬æ¢ç¼ºå°‘åŸå­æ€§ä¿æŠ¤

**ä½ç½®**: `internal/task/task.go:221-229`

```go
func (t *Task) Stop() error {
    t.mu.Lock()
    if t.state != StateRunning {
        t.mu.Unlock()  // âš ï¸ é‡Šæ”¾é”åè¿˜æœ‰åç»­æ“ä½œ
        return fmt.Errorf("task not running")
    }
    t.state = StateStopping
    t.mu.Unlock()  // âŒ é”é‡Šæ”¾è¿‡æ—©

    // ä¸‹é¢çš„ Stop æ“ä½œæœªè¢«é”ä¿æŠ¤
    for i, cap := range t.Capturers {
        // ...
    }
}
```

**é—®é¢˜**: åœ¨å¤š goroutine å¹¶å‘è°ƒç”¨ `Stop()` æ—¶ï¼Œå¯èƒ½å‡ºç°ï¼š
- Goroutine A æ£€æŸ¥ state = Runningï¼Œé‡Šæ”¾é”
- Goroutine B ä¹Ÿæ£€æŸ¥ state = Runningï¼ˆA å°šæœªä¿®æ”¹ï¼‰ï¼Œé‡Šæ”¾é”
- A å’Œ B åŒæ—¶æ‰§è¡Œ Stop é€»è¾‘

**ä¿®å¤**: æ‰©å¤§é”çš„èŒƒå›´æˆ–ä½¿ç”¨ `defer`ï¼š

```go
t.mu.Lock()
defer t.mu.Unlock()

if t.state != StateRunning {
    return fmt.Errorf("task not running")
}
t.state = StateStopping

// Capturer stop æ“ä½œä¹Ÿåº”åœ¨é”å†…
for i, cap := range t.Capturers {
    // ...
}
```

---

### 2.7 ä½å±ï¼šParser CanHandle() æ€§èƒ½æœªè¾¾åˆ°è®¾è®¡ç›®æ ‡

æ¶æ„æ–‡æ¡£è¦æ±‚ `CanHandle()` æ‰§è¡Œæ—¶é—´ **<50ns**ï¼Œä½†å®é™…å®ç°ä¸­ï¼š

**ä½ç½®**: `plugins/parser/sip/sip.go:88-100`

```go
func (p *SIPParser) CanHandle(pkt *models.DecodedPacket) bool {
    // 1. ç±»å‹æ–­è¨€
    if pkt.Transport.Protocol != models.ProtocolUDP {  // ~5ns
        return false
    }
    
    // 2. ç«¯å£æ£€æŸ¥
    srcPort := pkt.Transport.SrcPort  // ~5ns
    dstPort := pkt.Transport.DstPort
    
    // 3. FlowRegistry æŸ¥æ‰¾ï¼ˆsync.Map.Loadï¼‰
    if p.flowReg != nil {
        key := makeFlowKey(pkt)  // ~20nsï¼ˆæ„é€  stringï¼‰
        if _, ok := p.flowReg.Get(key); ok {  // ~30nsï¼ˆsync.Mapï¼‰
            return true
        }
    }
    
    // 4. ç«¯å£åŒ¹é…
    return srcPort == 5060 || dstPort == 5060  // ~5ns
}
```

**æ€»è€—æ—¶**: ~65nsï¼ˆè¶…å‡ºç›®æ ‡ 30%ï¼‰

**ç“¶é¢ˆ**: 
- `sync.Map.Load()` éå¸¸é‡æ—¶é—´ï¼ˆå¹³å‡ 30nsï¼Œæœ€åå¯è¾¾ 100ns+ï¼‰
- `makeFlowKey()` çš„å­—ç¬¦ä¸²æ‹¼æ¥æœ‰åˆ†é…å¼€é”€

**ä¼˜åŒ–å»ºè®®**:
1. å…ˆæ£€æŸ¥ç«¯å£ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰ï¼Œå†æŸ¥ FlowRegistry
2. ä½¿ç”¨ `[5]uint64` ä½œä¸º keyï¼ˆé¿å…å­—ç¬¦ä¸²åˆ†é…ï¼‰

---

### 2.8 ä½å±ï¼šç¡¬ç¼–ç  Channel å®¹é‡æœªé…ç½®åŒ–

**ä½ç½®**: `internal/task/task.go:90, 97, 107`

```go
t.captureCh = make(chan *models.RawPacket, 1000)      // TODO: é…ç½®åŒ–
t.sendBuffer = make(chan *models.OutputPacket, 10000) // TODO: é…ç½®åŒ–
```

**å½±å“**: 
- åœ¨é«˜æµé‡åœºæ™¯ï¼ˆ>100K ppsï¼‰å¯èƒ½å¯¼è‡´ä¸¢åŒ…
- æ— æ³•æ ¹æ®ç¡¬ä»¶èµ„æºï¼ˆå†…å­˜å¤§å°ï¼‰è°ƒæ•´

**è®¾è®¡æ–‡æ¡£**: `doc/config-design.md` æåˆ° `backpressure.pipeline_channel.capacity` é…ç½®ï¼Œä½†æœªå®ç°ã€‚

**ä¿®å¤**: ä»é…ç½®è¯»å–ï¼š

```go
// internal/task/task.go
captureChSize := viper.GetInt("backpressure.pipeline_channel.capacity")
if captureChSize == 0 {
    captureChSize = 1000  // é»˜è®¤å€¼
}
t.captureCh = make(chan *models.RawPacket, captureChSize)
```

---

## ä¸‰ã€æ€§èƒ½è¯„ä¼°

### 3.1 ååé‡åˆ†æ

**è®¾è®¡ç›®æ ‡**ï¼ˆfrom README.mdï¼‰:
- å¿«é€Ÿè·¯å¾„: â‰¥2M pps/core
- æ…¢é€Ÿè·¯å¾„ï¼ˆSIP è§£æï¼‰: â‰¥200K pps/core

**ç“¶é¢ˆè¯†åˆ«**:

| ç»„ä»¶ | ç†è®ºæ€§èƒ½ | å®é™…ç“¶é¢ˆ | ä¼˜åŒ–ç©ºé—´ |
|------|---------|---------|---------|
| AF_PACKET Capturer | 1M+ pps | âœ… æ— ç“¶é¢ˆï¼ˆå†…æ ¸ä¼˜åŒ–è‰¯å¥½ï¼‰ | - |
| L2-L4 Decoder | 5M+ pps | âœ… æ— ç“¶é¢ˆï¼ˆgopacket é«˜æ•ˆï¼‰ | - |
| Pipeline Dispatch | 2M+ pps | âš ï¸ `flowHash()` ~100ns | ä¼˜åŒ–å“ˆå¸Œç®—æ³• |
| SIP Parser | 200K pps | âš ï¸ æ­£åˆ™åŒ¹é…æ…¢ | æ›¿æ¢ä¸ºçŠ¶æ€æœº |
| Kafka Reporter | 50K pps | âŒ **æ‰¹å¤„ç†æœªå®ç°** | **é«˜ä¼˜å…ˆçº§ä¼˜åŒ–** |

**å…³é”®å‘ç°**: 

1. **Kafka Reporter æˆä¸ºæœ€å¤§ç“¶é¢ˆ**

   **ä½ç½®**: `plugins/reporter/kafka/kafka.go:85-107`

   ```go
   func (r *KafkaReporter) Report(ctx context.Context, pkt *models.OutputPacket) error {
       msg := kafka.Message{
           Topic: r.topic,
           Key:   []byte(pkt.TaskID),
           Value: data,  // JSON åºåˆ—åŒ–
       }
       
       // âŒ æ¯ä¸ªåŒ…éƒ½è°ƒç”¨ä¸€æ¬¡ WriteMessagesï¼ˆæ— æ‰¹å¤„ç†ï¼‰
       return r.writer.WriteMessages(ctx, msg)
   }
   ```

   **æ€§èƒ½å½±å“**:
   - æ¯æ¬¡è°ƒç”¨æ¶‰åŠ 1 æ¬¡ç½‘ç»œ RTTï¼ˆ~1msï¼‰
   - **æœ€å¤§ååé‡ = 1000 pps**ï¼ˆè¿œä½äºè®¾è®¡ç›®æ ‡ï¼‰
   
   **å¯¹æ¯”ä¸šç•Œæœ€ä½³å®è·µ**:
   ```go
   // Sarama/Kafka-go æ¨èæ‰¹å¤„ç†
   batch := make([]kafka.Message, 0, 100)
   ticker := time.NewTicker(100 * time.Millisecond)
   
   for {
       select {
       case pkt := <-input:
           batch = append(batch, toMessage(pkt))
           if len(batch) >= 100 {
               r.writer.WriteMessages(ctx, batch...)
               batch = batch[:0]
           }
       case <-ticker.C:
           if len(batch) > 0 {
               r.writer.WriteMessages(ctx, batch...)
               batch = batch[:0]
           }
       }
   }
   ```

2. **flowHash() æ€§èƒ½æœªè¾¾æ ‡**

   **ä½ç½®**: `internal/task/task.go:335-381`

   ```go
   func flowHash(pkt *models.RawPacket) uint32 {
       // âŒ ä½¿ç”¨ encoding/binary + crc32ï¼ˆ~100nsï¼‰
       var buf bytes.Buffer
       binary.Write(&buf, binary.BigEndian, pkt.SrcIP)
       binary.Write(&buf, binary.BigEndian, pkt.DstIP)
       // ...
       return crc32.ChecksumIEEE(buf.Bytes())
   }
   ```

   **ä¼˜åŒ–æ–¹æ¡ˆ**ï¼ˆxxhashï¼Œ~20nsï¼‰:
   ```go
   import "github.com/cespare/xxhash/v2"
   
   func flowHash(pkt *models.RawPacket) uint32 {
       h := xxhash.New()
       h.Write(pkt.SrcIP.AsSlice())  // netip.Addr é›¶æ‹·è´
       h.Write(pkt.DstIP.AsSlice())
       binary.Write(h, binary.LittleEndian, pkt.SrcPort)
       binary.Write(h, binary.LittleEndian, pkt.DstPort)
       h.Write([]byte{pkt.Protocol})
       return uint32(h.Sum64())
   }
   ```

---

### 3.2 å†…å­˜å ç”¨åˆ†æ

**è®¾è®¡ç›®æ ‡**: â‰¤512 MB åŸºå‡†å†…å­˜

**å®é™…åˆ†æ**ï¼ˆé€šè¿‡ä»£ç å®¡æŸ¥ï¼‰:

| ç»„ä»¶ | é¢„ä¼°å†…å­˜ | ä¾æ® |
|------|---------|-----|
| **Channel ç¼“å†²åŒº** | 200 MB | `10000 * (1500 bytes + 200 bytes å…ƒæ•°æ®) * 2 pipelines` |
| **Flow Registry** | 50 MB | `10000 flows * 5KB/flow`ï¼ˆSIP session çŠ¶æ€ï¼‰ |
| **Kafka Writer** | 64 MB | é»˜è®¤ç¼“å†²åŒºï¼ˆkafka-goï¼‰ |
| **å…¶ä»–ï¼ˆæ ˆã€å †ï¼‰** | 50 MB | Go runtime |
| **æ€»è®¡** | ~364 MB | âœ… ç¬¦åˆç›®æ ‡ |

**é£é™©ç‚¹**:
- å¦‚æœ Flow Registry æœªè®¾ç½® TTL æ¸…ç†ï¼Œå¯èƒ½æ— é™å¢é•¿
  
  **ä½ç½®**: `plugins/parser/sip/sip.go:22-24`
  ```go
  const (
      sessionTTL        = 30 * time.Minute  // âœ… å·²è®¾ç½®
      cleanupInterval   = 5 * time.Minute   // âœ… å®šæœŸæ¸…ç†
  )
  ```

---

### 3.3 å»¶è¿Ÿåˆ†æ

**è®¾è®¡ç›®æ ‡**: P99 < 1ms

**ç†è®ºè®¡ç®—**ï¼ˆå•åŒ…å¤„ç†é“¾è·¯ï¼‰:

| é˜¶æ®µ | è€—æ—¶ | ç´¯ç§¯ |
|------|------|------|
| Capture (AF_PACKET) | ~10Âµs | 10Âµs |
| L2-L4 Decode | ~1Âµs | 11Âµs |
| Parser.CanHandle() | ~65ns | 11.065Âµs |
| Parser.Handle() (SIP) | ~10Âµs | 21Âµs |
| Processor (Filter) | ~500ns | 21.5Âµs |
| Channel Send | ~100ns | 21.6Âµs |
| Sender Dequeue | ~100ns | 21.7Âµs |
| Reporter (Kafka) | **1ms** | **1.02ms** âŒ |

**ç»“è®º**: 
- éæ‰¹å¤„ç†æ¨¡å¼ä¸‹ï¼ŒP50 å»¶è¿Ÿ = 1.02msï¼ˆè¶…æ ‡ï¼‰
- æ‰¹å¤„ç†ä¼˜åŒ–åå¯é™è‡³ ~50Âµs

---

## å››ã€å¯ç»´æŠ¤æ€§è¯„ä¼°

### 4.1 ä»£ç é‡å¤åº¦

**ä¸¥é‡é—®é¢˜**: Plugin Registry çš„æ¨¡æ¿ä»£ç 

**ä½ç½®**: `pkg/plugin/registry.go:30-86`

4 ç§æ’ä»¶ç±»å‹ï¼ˆCapturer/Parser/Processor/Reporterï¼‰æœ‰å®Œå…¨ç›¸åŒçš„æ³¨å†Œé€»è¾‘ï¼š

```go
// é‡å¤ 4 æ¬¡çš„æ¨¡å¼
var capturers = make(map[string]CapturerFactory)
var capturersMu sync.RWMutex

func RegisterCapturer(name string, factory CapturerFactory) {
    capturersMu.Lock()
    defer capturersMu.Unlock()
    if _, exists := capturers[name]; exists {
        panic(fmt.Sprintf("capturer already registered: %s", name))
    }
    capturers[name] = factory
}

// ... GetCapturer, ListCapturersï¼ˆåŒæ ·æ¨¡å¼ï¼‰
```

**æ”¹è¿›å»ºè®®**ï¼ˆä½¿ç”¨ Go 1.18+ æ³›å‹ï¼‰:

```go
// pkg/plugin/registry.go
type Registry[T any] struct {
    factories map[string]T
    mu        sync.RWMutex
}

func (r *Registry[T]) Register(name string, factory T) {
    r.mu.Lock()
    defer r.mu.Unlock()
    if _, exists := r.factories[name]; exists {
        panic(fmt.Sprintf("plugin already registered: %s", name))
    }
    r.factories[name] = factory
}

// ä½¿ç”¨
var Capturers = &Registry[CapturerFactory]{factories: make(map[string]CapturerFactory)}
var Parsers = &Registry[ParserFactory]{factories: make(map[string]ParserFactory)}
```

**æ”¶ç›Š**: ä»£ç å‡å°‘ **60%**ï¼ˆä» 200 è¡Œé™è‡³ 80 è¡Œï¼‰

---

### 4.2 é”™è¯¯å¤„ç†ä¸€è‡´æ€§

**é—®é¢˜**: 3 ç§ä¸åŒçš„é”™è¯¯å¤„ç†ç­–ç•¥æ··ç”¨

| ç­–ç•¥ | ç¤ºä¾‹ä½ç½® | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|
| **è¿”å›é”™è¯¯** | `task.Start()` | âœ… å¯æ¢å¤é”™è¯¯ |
| **è®°å½• + ç»§ç»­** | `statsCollectorLoop()` | âš ï¸ éå…³é”®è·¯å¾„ |
| **Panic** | `registry.go` | âŒ ç¨‹åºåˆå§‹åŒ–å¤±è´¥ |

**ä¸ä¸€è‡´ç¤ºä¾‹**:

```go
// internal/task/task.go:236 - è®°å½•è­¦å‘Š
if err := cap.Stop(ctx); err != nil {
    slog.Warn("error stopping capturer", "error", err)
}

// internal/task/task.go:169 - è¿”å›é”™è¯¯
if err := rep.Start(ctx); err != nil {
    return fmt.Errorf("start reporter %d failed: %w", i, err)
}
```

**å»ºè®®**: åˆ¶å®šé”™è¯¯åˆ†çº§æ ‡å‡†ï¼ˆCritical/Major/Minorï¼‰ï¼Œç»Ÿä¸€å¤„ç†ç­–ç•¥ã€‚

---

### 4.3 æµ‹è¯•è¦†ç›–ç‡

**å½“å‰çŠ¶æ€**ï¼ˆé€šè¿‡æ–‡ä»¶è®¡æ•°ï¼‰:
- æ€»ä»£ç æ–‡ä»¶: ~80 ä¸ª `.go`
- æµ‹è¯•æ–‡ä»¶: 23 ä¸ª `*_test.go`
- **è¦†ç›–ç‡**: ~28%ï¼ˆä¼°ç®—ï¼‰

**å…³é”®ç¼ºå¤±**:

| æ¨¡å— | æµ‹è¯•çŠ¶æ€ | é£é™© |
|------|---------|-----|
| `internal/task/task.go` | âŒ æ—  `dispatchLoop()` æµ‹è¯• | é«˜ |
| `internal/pipeline/pipeline.go` | âš ï¸ ä»…åŸºç¡€æµ‹è¯• | ä¸­ |
| `plugins/parser/sip/sip.go` | âœ… æœ‰å•å…ƒæµ‹è¯• | ä½ |
| `internal/daemon/daemon.go` | âŒ æ— é›†æˆæµ‹è¯• | é«˜ |

**ç¤ºä¾‹ç¼ºå¤±æµ‹è¯•**:

```go
// åº”è¡¥å……çš„æµ‹è¯•ï¼ˆinternal/task/task_test.goï¼‰
func TestDispatchLoop_HashDistribution(t *testing.T) {
    // éªŒè¯ flowHash æ˜¯å¦å‡åŒ€åˆ†å¸ƒåˆ°å„ pipeline
}

func TestTask_StopWithPartialStart(t *testing.T) {
    // éªŒè¯ç¬¬ 3 ä¸ª Reporter å¯åŠ¨å¤±è´¥æ—¶çš„æ¸…ç†
}
```

---

### 4.4 æ–‡æ¡£å®Œæ•´æ€§

**ä¼˜ç‚¹**:
- âœ… æ¶æ„æ–‡æ¡£è¯¦å°½ï¼ˆ`doc/architecture.md` 88KBï¼‰
- âœ… éƒ¨ç½²æŒ‡å—å®Œå–„ï¼ˆ`docs/DEPLOYMENT.md`ï¼‰
- âœ… README ç¤ºä¾‹ä¸°å¯Œ

**ä¸è¶³**:
- âŒ ä»£ç æ³¨é‡Šä¸è¶³ï¼ˆå…³é”®ç®—æ³•å¦‚ `flowHash()` æ— æ–‡æ¡£ï¼‰
- âŒ ç¼ºå°‘ API æ–‡æ¡£ï¼ˆPlugin æ¥å£æœªç”Ÿæˆ godocï¼‰
- âš ï¸ éƒ¨åˆ† TODO æ³¨é‡Šæœªè·Ÿè¸ªï¼ˆ23 å¤„ TODOï¼Œæ—  Issue å…³è”ï¼‰

**å»ºè®®**: 
1. æ·»åŠ  `make doc` ç”Ÿæˆ godoc
2. å°† TODO è½¬ä¸º GitHub Issues

---

## äº”ã€å¯æ‰©å±•æ€§è¯„ä¼°

### 5.1 æ’ä»¶ç³»ç»Ÿé™åˆ¶

**ä¸¥é‡é™åˆ¶**: å•ä»»åŠ¡çº¦æŸ

**ä½ç½®**: `internal/task/manager.go:48`

```go
func (m *Manager) CreateTask(config *models.TaskConfig) error {
    if len(m.tasks) > 0 {
        return fmt.Errorf("only one task supported in Phase 1")  // âŒ ç¡¬ç¼–ç é™åˆ¶
    }
    // ...
}
```

**å½±å“**:
- æ— æ³•åŒæ—¶æ•è·å¤šä¸ªæ¥å£
- æ— æ³•è¿è¡Œä¸åŒåè®®çš„ä»»åŠ¡ï¼ˆå¦‚ SIP + DNSï¼‰
- é™åˆ¶æ°´å¹³æ‰©å±•èƒ½åŠ›

**ç§»é™¤éš¾åº¦**: **ä½**ï¼ˆä»…éœ€åˆ é™¤è¯¥æ£€æŸ¥ï¼ŒTask å·²æ”¯æŒå¹¶å‘è¿è¡Œï¼‰

**æ¶æ„è®¾è®¡**: æ–‡æ¡£ä¸­æåˆ° "N ä¸ªç‹¬ç«‹ Task"ï¼Œè¯´æ˜è¿™æ˜¯**ä¸´æ—¶é™åˆ¶**ï¼Œéè®¾è®¡ç¼ºé™·ã€‚

---

### 5.2 æ’ä»¶ç”Ÿå‘½å‘¨æœŸä¸è¶³

**å½“å‰æ¥å£**: `pkg/plugin/lifecycle.go`

```go
type Lifecycle interface {
    Init(config map[string]interface{}) error
    Start(ctx context.Context) error
    Stop(ctx context.Context) error
}
```

**ç¼ºå¤±èƒ½åŠ›**:

| éœ€æ±‚ | å½“å‰æ”¯æŒ | å½±å“ |
|------|---------|-----|
| çƒ­æ›´æ–°è¿‡æ»¤è§„åˆ™ | âŒ | å¿…é¡»é‡å¯ä»»åŠ¡ |
| æš‚åœ/æ¢å¤æŠ“åŒ… | âŒ | æ— æ³•ä¸´æ—¶åœæ­¢é«˜è´Ÿè½½ä»»åŠ¡ |
| åŠ¨æ€è°ƒæ•´ Kafka topic | âŒ | é…ç½®å˜æ›´éœ€é‡å¯ |

**æ‰©å±•å»ºè®®**:

```go
type Lifecycle interface {
    Init(config map[string]interface{}) error
    Start(ctx context.Context) error
    Stop(ctx context.Context) error
    
    // æ–°å¢
    Pause() error                              // æš‚åœå¤„ç†
    Resume() error                             // æ¢å¤å¤„ç†
    Reconfigure(config map[string]interface{}) error  // åŠ¨æ€æ›´æ–°é…ç½®
}
```

---

### 5.3 Dispatcher ç­–ç•¥å›ºåŒ–

**é—®é¢˜**: æ— æ³•æ›¿æ¢è´Ÿè½½å‡è¡¡ç®—æ³•

**å½“å‰è®¾è®¡**: `flowHash()` ç¡¬ç¼–ç åœ¨ Task ä¸­ï¼Œæ— æ³•åˆ‡æ¢ä¸ºï¼š
- Round-robinï¼ˆè½®è¯¢ï¼Œé€‚åˆå‡åŒ€æµé‡ï¼‰
- Weightedï¼ˆåŠ æƒï¼Œé€‚åˆå¼‚æ„ Pipelineï¼‰
- Least-connectionï¼ˆæœ€å°‘è¿æ¥ï¼Œé€‚åˆé•¿è¿æ¥åœºæ™¯ï¼‰

**å»ºè®®æ¶æ„**:

```go
// pkg/plugin/dispatcher.goï¼ˆæ–°å¢ï¼‰
type Dispatcher interface {
    Dispatch(pkt *models.RawPacket, pipelines int) int  // è¿”å› pipeline ç´¢å¼•
}

// plugins/dispatcher/hash/hash.go
type HashDispatcher struct{}
func (d *HashDispatcher) Dispatch(pkt *models.RawPacket, n int) int {
    return int(flowHash(pkt) % uint32(n))
}

// plugins/dispatcher/roundrobin/roundrobin.go
type RoundRobinDispatcher struct {
    counter atomic.Uint64
}
func (d *RoundRobinDispatcher) Dispatch(pkt *models.RawPacket, n int) int {
    return int(d.counter.Add(1) % uint64(n))
}
```

**é…ç½®ç¤ºä¾‹**:

```yaml
tasks:
  - id: sip-capture
    dispatch:
      mode: dispatch
      strategy: hash  # æˆ– roundrobin, weighted
```

---

### 5.4 Flow Registry ç±»å‹ä¸å®‰å…¨

**é—®é¢˜**: `sync.Map` çš„ `interface{}` key/value æ˜“å‡ºé”™

**ä½ç½®**: `internal/task/flow_registry.go:42-45`

```go
func (r *FlowRegistry) Get(key interface{}) (interface{}, bool) {
    return r.flows.Load(key)  // âŒ è¿è¡Œæ—¶ç±»å‹æ£€æŸ¥
}
```

**é£é™©**:
- Parser A ä½¿ç”¨ `string` keyï¼ŒParser B ä½¿ç”¨ `struct` key â†’ å†²çª
- ç¼–è¯‘æ—¶æ— æ³•æ£€æµ‹ç±»å‹é”™è¯¯

**Go 1.18+ æ”¹è¿›**:

```go
type FlowRegistry[K comparable, V any] struct {
    flows sync.Map  // æˆ– map[K]V + sync.RWMutex
}

func (r *FlowRegistry[K, V]) Register(key K, value V) {
    r.flows.Store(key, value)  // âœ… ç¼–è¯‘æ—¶ç±»å‹å®‰å…¨
}
```

---

### 5.5 Parser ç¼“å­˜è€¦åˆ

**é—®é¢˜**: SIP Parser ç›´æ¥ä¾èµ– `go-cache` åº“

**ä½ç½®**: `plugins/parser/sip/sip.go:29`

```go
import "github.com/patrickmn/go-cache"

type SIPParser struct {
    sessions *cache.Cache  // âŒ ç¡¬ç¼–ç ç¼“å­˜å®ç°
}
```

**å½±å“**:
- æ— æ³•æ›¿æ¢ä¸º Redisï¼ˆåˆ†å¸ƒå¼åœºæ™¯ï¼‰
- æ— æ³• Mock æµ‹è¯•
- å¢åŠ æ’ä»¶é—´è€¦åˆ

**è§£è€¦æ–¹æ¡ˆ**:

```go
// pkg/plugin/cache.goï¼ˆæ–°å¢æ¥å£ï¼‰
type Cache interface {
    Set(key string, value interface{}, ttl time.Duration)
    Get(key string) (interface{}, bool)
    Delete(key string)
}

// SIP Parser ä½¿ç”¨æ¥å£
type SIPParser struct {
    sessions Cache  // âœ… å¯æ›¿æ¢
}
```

---

## å…­ã€å®‰å…¨æ€§è¯„ä¼°

### 6.1 æ‹’ç»æœåŠ¡é£é™©

**æ½œåœ¨æ”»å‡»**: IP åˆ†ç‰‡è€—å°½å†…å­˜

**ä½ç½®**: `doc/config-design.md` æåˆ°çš„é…ç½®

```yaml
core:
  decoder:
    ip_reassembly:
      max_fragments: 10000  # âš ï¸ å¯è¢«æ¶æ„åˆ†ç‰‡è€—å°½
```

**æ”»å‡»åœºæ™¯**:
1. æ”»å‡»è€…å‘é€å¤§é‡åˆ†ç‰‡åŒ…ï¼ˆæ¯ä¸ªåŒ… ID ä¸åŒï¼‰
2. `max_fragments` è¾¾åˆ°ä¸Šé™ â†’ åˆæ³•æµé‡æ— æ³•é‡ç»„
3. å†…å­˜å ç”¨: `10000 * 1500 bytes = 15 MB`ï¼ˆå¯æ¥å—ï¼‰

**ç¼“è§£æªæ–½**ï¼ˆå½“å‰ä»£ç æœªæ‰¾åˆ°å®ç°ï¼‰:
- âœ… è®¾ç½® `max_fragments` ä¸Šé™ï¼ˆå·²æœ‰ï¼‰
- âŒ æœªå®ç° Per-IP é™é€Ÿï¼ˆç¼ºå¤±ï¼‰
- âŒ æœªå®ç°åˆ†ç‰‡è¶…æ—¶æ¸…ç†ï¼ˆ`doc` æåˆ° 30sï¼Œä»£ç æœªæ‰¾åˆ°ï¼‰

**å»ºè®®**: åœ¨ `internal/core/decoder/reassembly.go` ä¸­å®ç°ï¼š

```go
type Reassembler struct {
    fragments map[FragmentID]*FragmentBuffer
    perIPLimit map[netip.Addr]int  // æ–°å¢ï¼šæ¯ IP é™åˆ¶
}

func (r *Reassembler) Add(frag Fragment) error {
    srcIP := frag.SrcIP
    if r.perIPLimit[srcIP] >= 100 {  // å• IP æœ€å¤š 100 ä¸ªåˆ†ç‰‡
        return fmt.Errorf("per-IP fragment limit exceeded")
    }
    // ...
}
```

---

### 6.2 é…ç½®æ³¨å…¥é£é™©

**ä½é£é™©**: Viper æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–

**ä½ç½®**: `internal/config/config.go`

```go
viper.AutomaticEnv()  // âš ï¸ æ‰€æœ‰é…ç½®å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–
```

**åœºæ™¯**: å®¹å™¨ç¯å¢ƒä¸­ï¼Œæ¶æ„å®¹å™¨å¯è®¾ç½® `OTUS_KAFKA_BROKERS=attacker.com` åŠ«æŒæ•°æ®ã€‚

**ç¼“è§£**: 
- âœ… ä½¿ç”¨ `viper.AllowEnvPrefix("OTUS_")` é™åˆ¶å‰ç¼€ï¼ˆå·²å®ç°ï¼‰
- âš ï¸ æ•æ„Ÿé…ç½®ï¼ˆå¦‚ Kafka TLSï¼‰åº”æ ¡éªŒè¯ä¹¦

---

## ä¸ƒã€ä¾èµ–åˆ†æ

### 7.1 å…³é”®ä¾èµ–

**from `go.mod`**:

| ä¾èµ– | ç‰ˆæœ¬ | ç”¨é€” | é£é™© |
|------|------|------|------|
| `github.com/google/gopacket` | v1.1.19 | åŒ…è§£æ | âš ï¸ éœ€è¦ CGOï¼ˆlibpcapï¼‰ |
| `github.com/segmentio/kafka-go` | v0.4.50 | Kafka å®¢æˆ·ç«¯ | âœ… ç¨³å®š |
| `github.com/prometheus/client_golang` | v1.23.2 | æŒ‡æ ‡æš´éœ² | âœ… å®˜æ–¹åº“ |
| `github.com/spf13/viper` | v1.20.1 | é…ç½®ç®¡ç† | âœ… æˆç†Ÿ |

**é—®é¢˜**: `gopacket` ä¾èµ– `libpcap-dev`ï¼ˆC åº“ï¼‰ï¼Œå½±å“ï¼š
- âŒ äº¤å‰ç¼–è¯‘å›°éš¾ï¼ˆéœ€è¦å¯¹åº”æ¶æ„çš„ libpcapï¼‰
- âŒ é™æ€é“¾æ¥å¤æ‚ï¼ˆmusl vs glibcï¼‰
- âœ… ä½†æ€§èƒ½ä¼˜å¼‚ï¼ˆå†…æ ¸ä¼˜åŒ–ï¼‰

**æ›¿ä»£æ–¹æ¡ˆ**: ä½¿ç”¨çº¯ Go å®ç°çš„ `afpacket`ï¼ˆå·²åœ¨ `plugins/capture/afpacket/` ä¸­éƒ¨åˆ†å®ç°ï¼‰ã€‚

---

### 7.2 æ„å»ºä¾èµ–

**æµ‹è¯•ç¼–è¯‘é”™è¯¯**ï¼ˆfrom ä¸Šè¿°æµ‹è¯•è¾“å‡ºï¼‰:

```
fatal error: pcap.h: No such file or directory
```

**å½±å“**: 
- CI/CD ç¯å¢ƒéœ€å®‰è£… `libpcap-dev`
- Docker æ„å»ºéœ€å¤šé˜¶æ®µï¼ˆbuilder + runtimeï¼‰

**Dockerfile æ£€æŸ¥**:

```bash
cat /home/runner/work/Otus/Otus/Dockerfile
```

---

## å…«ã€å…³é”®å»ºè®®

### 8.1 ç«‹å³ä¿®å¤ï¼ˆP0 - ç”Ÿäº§é˜»å¡ï¼‰

| é—®é¢˜ | æ–‡ä»¶ | è¡Œå· | é¢„è®¡å·¥æ—¶ |
|------|------|------|---------|
| Task å¯åŠ¨å¤±è´¥æ¸…ç† | `internal/task/manager.go` | 214-216 | 2 å°æ—¶ |
| statsCollectorLoop Delta é”™è¯¯ | `internal/task/task.go` | 470-521 | 3 å°æ—¶ |
| sendBuffer å…³é—­ç«æ€ | `internal/task/task.go` | 256-258 | 1 å°æ—¶ |

**æ€»è®¡**: 6 å°æ—¶ï¼ˆ1 ä¸ªå·¥ä½œæ—¥ï¼‰

---

### 8.2 çŸ­æœŸä¼˜åŒ–ï¼ˆP1 - 2 å‘¨å†…å®Œæˆï¼‰

1. **Kafka Reporter æ‰¹å¤„ç†**ï¼ˆæ€§èƒ½æå‡ 100xï¼‰
   - æ–‡ä»¶: `plugins/reporter/kafka/kafka.go`
   - å·¥æ—¶: 4 å°æ—¶

2. **é…ç½®åŒ–ç¡¬ç¼–ç å€¼**
   - Channel å®¹é‡: `internal/task/task.go`
   - Stats é—´éš”: `internal/task/task.go:472`
   - å·¥æ—¶: 3 å°æ—¶

3. **è¡¥å……å•å…ƒæµ‹è¯•**
   - `dispatchLoop()` æµ‹è¯•
   - `flowHash()` åˆ†å¸ƒå‡åŒ€æ€§æµ‹è¯•
   - å·¥æ—¶: 8 å°æ—¶

---

### 8.3 ä¸­æœŸæ”¹è¿›ï¼ˆP2 - ä¸‹ä¸€ç‰ˆæœ¬ï¼‰

1. **ç§»é™¤å•ä»»åŠ¡é™åˆ¶**
   - å·¥æ—¶: 1 å°æ—¶ï¼ˆä»…åˆ é™¤æ£€æŸ¥ï¼‰

2. **å®ç° Dispatcher ç­–ç•¥æ¨¡å¼**
   - å·¥æ—¶: 12 å°æ—¶

3. **Plugin Registry æ³›å‹é‡æ„**
   - å·¥æ—¶: 6 å°æ—¶

---

### 8.4 é•¿æœŸè§„åˆ’ï¼ˆP3 - æœªæ¥ç‰ˆæœ¬ï¼‰

1. **çƒ­åŠ è½½æ”¯æŒ**
   - é…ç½®æ–‡ä»¶å˜æ›´è‡ªåŠ¨é‡è½½
   - å·¥æ—¶: 20 å°æ—¶

2. **å¢å¼º Plugin ç”Ÿå‘½å‘¨æœŸ**
   - æ·»åŠ  Pause/Resume/Reconfigure
   - å·¥æ—¶: 16 å°æ—¶

3. **å®Œå–„ IPv4 é‡ç»„**
   - å½“å‰ä»…æ¡†æ¶ï¼Œæœªå®ç°æ ¸å¿ƒé€»è¾‘
   - å·¥æ—¶: 24 å°æ—¶

---

## ä¹ã€æ€»ç»“

### 9.1 ä¼˜ç‚¹

1. **æ¶æ„è®¾è®¡ä¼˜ç§€**
   - æ’ä»¶åŒ–è®¾è®¡æ¸…æ™°ï¼Œæ‰©å±•ç‚¹æ˜ç¡®
   - å•çº¿ç¨‹ Pipeline é¿å…é”ç«äº‰
   - é™æ€ç¼–è¯‘ä¾¿äºéƒ¨ç½²

2. **æ–‡æ¡£å®Œå–„**
   - 88KB æ¶æ„æ–‡æ¡£
   - è¯¦ç»†çš„è®¾è®¡å†³ç­–è¯´æ˜

3. **æ€§èƒ½ç›®æ ‡åˆç†**
   - 2M pps ç›®æ ‡å¯è¾¾æˆï¼ˆéœ€ä¿®å¤ Kafka æ‰¹å¤„ç†ï¼‰

### 9.2 ä¸»è¦é—®é¢˜

1. **å®ç°è´¨é‡ä¸è¶³**
   - 3 ä¸ªé«˜å± Bugï¼ˆèµ„æºæ³„æ¼ã€ç«æ€ã€æŒ‡æ ‡é”™è¯¯ï¼‰
   - é”™è¯¯å¤„ç†ä¸ä¸€è‡´
   - æµ‹è¯•è¦†ç›–ç‡ä½ï¼ˆ~28%ï¼‰

2. **æ€§èƒ½ç“¶é¢ˆæ˜æ˜¾**
   - Kafka Reporter æ— æ‰¹å¤„ç†ï¼ˆé™åˆ¶åœ¨ 1K ppsï¼‰
   - éƒ¨åˆ†ç¡¬ç¼–ç é™åˆ¶æ‰©å±•æ€§

3. **ç”Ÿäº§å°±ç»ªåº¦ä¸è¶³**
   - ç¼ºå°‘å¥å£®çš„é”™è¯¯æ¢å¤
   - éƒ¨åˆ†åŠŸèƒ½æœªå®ç°ï¼ˆå¦‚ IPv4 é‡ç»„ï¼‰

### 9.3 å¯è¡Œæ€§è¯„ä¼°

**å½“å‰çŠ¶æ€**: **ä¸å»ºè®®ç›´æ¥ç”Ÿäº§éƒ¨ç½²**

**æ¨èè·¯å¾„**:
1. ä¿®å¤ P0 é—®é¢˜ï¼ˆ1 å¤©ï¼‰
2. å®Œæˆ P1 ä¼˜åŒ–ï¼ˆ2 å‘¨ï¼‰
3. è¡¥å……é›†æˆæµ‹è¯•ï¼ˆ1 å‘¨ï¼‰
4. è¿›è¡Œæ€§èƒ½å‹æµ‹ï¼ˆ1 å‘¨ï¼‰
5. **é¢„è®¡ 1 ä¸ªæœˆåå¯è¾¾ç”Ÿäº§çº§åˆ«**

### 9.4 è¯„åˆ†å¡

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **æ¶æ„è®¾è®¡** | â­â­â­â­â­ | ä¼˜ç§€çš„æ’ä»¶åŒ–ã€æ¨¡å—åŒ–è®¾è®¡ |
| **ä»£ç å®ç°** | â­â­â­ | å­˜åœ¨å…³é”® Bugï¼Œéœ€åŠ å¼ºæµ‹è¯• |
| **æ€§èƒ½** | â­â­â­â­ | æ¶æ„æ”¯æŒé«˜æ€§èƒ½ï¼Œéœ€ä¼˜åŒ– Reporter |
| **å¯ç»´æŠ¤æ€§** | â­â­â­ | æ–‡æ¡£å¥½ï¼Œä½†ä»£ç é‡å¤ã€æµ‹è¯•ä¸è¶³ |
| **å¯æ‰©å±•æ€§** | â­â­â­â­ | æ’ä»¶ç³»ç»Ÿçµæ´»ï¼Œéœ€ç§»é™¤ä¸´æ—¶é™åˆ¶ |
| **ç”Ÿäº§å°±ç»ª** | â­â­ | å…³é”® Bug æœªä¿®å¤ï¼Œä¸å»ºè®®ç›´æ¥ä¸Šçº¿ |

**ç»¼åˆè¯„åˆ†**: â­â­â­ (3/5)

---

## åã€é™„å½•

### A. å…³é”®æ–‡ä»¶æ¸…å•

| ç±»åˆ« | è·¯å¾„ | é‡è¦æ€§ | çŠ¶æ€ |
|------|------|--------|------|
| æ¶æ„æ–‡æ¡£ | `doc/architecture.md` | â­â­â­â­â­ | âœ… å®Œå–„ |
| ä»»åŠ¡ç®¡ç† | `internal/task/task.go` | â­â­â­â­â­ | âš ï¸ æœ‰ Bug |
| æ’ä»¶æ³¨å†Œ | `pkg/plugin/registry.go` | â­â­â­â­ | âš ï¸ éœ€é‡æ„ |
| Kafka Reporter | `plugins/reporter/kafka/kafka.go` | â­â­â­â­ | âŒ æ€§èƒ½å·® |
| Daemon æ§åˆ¶ | `internal/daemon/daemon.go` | â­â­â­â­ | âš ï¸ æœ‰æ³„æ¼ |

### B. Metrics æ¸…å•

**å½“å‰å®ç°çš„æŒ‡æ ‡**:

```promql
# Capture
otus_capture_packets_total{task, capturer}
otus_capture_drops_total{task, capturer, stage}

# Pipeline
otus_pipeline_packets_total{task, pipeline, stage}
otus_pipeline_latency_seconds{task, stage}

# Task
otus_task_status{task, status}
```

**å»ºè®®æ–°å¢**:

```promql
# ä»»åŠ¡çº§èšåˆ
otus_task_packets_total{task}
otus_task_throughput_pps{task}

# Reporter æ€§èƒ½
otus_reporter_batch_size{task, reporter}
otus_reporter_errors_total{task, reporter, error_type}

# Flow Registry
otus_flow_registry_size{task}
otus_flow_registry_evictions_total{task}
```

### C. æµ‹è¯•å»ºè®®

**ä¼˜å…ˆè¡¥å……çš„æµ‹è¯•ç”¨ä¾‹**:

```go
// 1. Task ç”Ÿå‘½å‘¨æœŸ
TestTask_StartFailureRollback(t *testing.T)
TestTask_StopIdempotency(t *testing.T)
TestTask_ConcurrentStop(t *testing.T)

// 2. Pipeline
TestPipeline_Backpressure(t *testing.T)
TestPipeline_ContextCancellation(t *testing.T)

// 3. Dispatcher
TestDispatchLoop_HashDistribution(t *testing.T)
TestDispatchLoop_ZeroPipelines(t *testing.T)

// 4. Stats
TestStatsCollector_MultipleCapturers(t *testing.T)
TestStatsCollector_CounterReset(t *testing.T)

// 5. Daemon
TestDaemon_GracefulShutdown(t *testing.T)
TestDaemon_SignalHandling(t *testing.T)
```

---

**æŠ¥å‘Šç»“æŸ**

å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–æäº¤ Issueï¼šhttps://github.com/firestige/Otus/issues
